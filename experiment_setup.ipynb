{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e98a7a3-26d3-4d8e-9dc6-0426d0222b7d",
   "metadata": {},
   "source": [
    "Programmatic way to generate config files for a given hyperparameter sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d679a7-755b-43f0-8546-f4fcbe5fdf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95986d9-efd0-49a6-a217-60eecac445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a directory for experiment\n",
    "\n",
    "sweep_experiment_name = \"sweep_1\"\n",
    "sweep_experiment_dir_parent = \"/home/jupyter/\"\n",
    "sweep_experiment_dir = os.path.join(sweep_experiment_dir_parent, sweep_experiment_name)\n",
    "\n",
    "if not os.path.exists(sweep_experiment_dir):\n",
    "    os.makedirs(sweep_experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71a7653-4aef-41e4-97f3-7097fb4ff310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model type\n",
    "\n",
    "model_type = 'eskmeans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f49dc7d-886e-4163-a06f-e1ac82214e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workhorse to generate combinations of parameters\n",
    "\n",
    "def generate_choice_combinations(d):\n",
    "    # d is a dict of lists\n",
    "    # require that the keys of d are all of the same type (eg strings)\n",
    "    # output a dict {i:{key:value} for i in range(N)}\n",
    "    # which contains all possible combinations of values (encoded in the lists)\n",
    "    # and N = product of len(d[key]), for all keys in d\n",
    "    sorted_keys = sorted(d.keys())\n",
    "    choices_lex = []\n",
    "    num_choices = {}\n",
    "    for key in sorted_keys:\n",
    "        num_choices[key] = len(d[key])\n",
    "        choices_lex.append(list(range(num_choices[key])))\n",
    "    choices_cartesian = list(itertools.product(*choices_lex))\n",
    "    configs_cartesian = {}\n",
    "    for i, choices in enumerate(choices_cartesian):\n",
    "        configs_cartesian[i] = {sorted_keys[j]: d[sorted_keys[j]][choices[j]] for j in range(len(sorted_keys))}\n",
    "        \n",
    "    return configs_cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060353b6-48c0-4f0c-9df5-0269d262c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify general parameters\n",
    "\n",
    "sweep_config = {}\n",
    "sweep_config['input_vars'] = [['AccX', 'AccY', 'AccZ', 'Depth']]\n",
    "sweep_config['metadata_fp'] = ['/home/jupyter/behavior_data_local/data/formatted/ladds_seals/dataset_metadata.yaml']\n",
    "sweep_config['model'] = [model_type] # do not change\n",
    "sweep_config['output_parent_dir'] = [sweep_experiment_dir]\n",
    "sweep_config['test_data_fp_glob'] = [['/home/jupyter/behavior_data_local/data/formatted/ladds_seals/clip_data/*.npy']]\n",
    "sweep_config['train_data_fp_glob'] = [['/home/jupyter/behavior_data_local/data/formatted/ladds_seals/clip_data/*.npy']]\n",
    "sweep_config['num_clusters'] = [8, 20]\n",
    "sweep_config['read_latents'] = [True] # should be either [True] or [False]\n",
    "sweep_config['train_data_latents_fp_glob'] = [['/home/jupyter/behavior_benchmarks_outputs/ladds_seals/whiten_seals/latents/*.npy']]\n",
    "sweep_config['test_data_latents_fp_glob'] = [['/home/jupyter/behavior_benchmarks_outputs/ladds_seals/whiten_seals/latents/*.npy']]\n",
    "\n",
    "summary = sweep_config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7f672d-fcee-4c55-bc0e-94c9696cc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model-specific parameters\n",
    "\n",
    "if model_type == 'eskmeans':\n",
    "    sweep_model_config = {}\n",
    "    sweep_model_config['boundary_init_lambda'] = [30.0]\n",
    "    sweep_model_config['embed_length'] = [10]\n",
    "    sweep_model_config['landmark_hop_size'] = [5]\n",
    "    sweep_model_config['n_epochs'] = [6]\n",
    "    sweep_model_config['n_landmarks_max'] = [40]\n",
    "    sweep_model_config['batch_size'] = [1]\n",
    "    sweep_model_config['time_power_term'] = [.95, .8]\n",
    "    \n",
    "    summary['eskmeans_config'] = sweep_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe4b729-aee7-4f11-9d44-9294e9820ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify evaluation parameters\n",
    "sweep_evaluation_config = {}\n",
    "sweep_evaluation_config['boundary_tolerance_sec'] = [1.]\n",
    "\n",
    "summary['evaluation'] = sweep_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43d59aea-074a-4f94-8180-c5e80cd46ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize what the experiment is about and save off\n",
    "\n",
    "summary['summary'] = \"First sweep with eskmeans\"\n",
    "target_filename = sweep_experiment_name + \"_summary\" + '.yaml'\n",
    "target_fp = os.path.join(sweep_experiment_dir, target_filename)                       \n",
    "with open(target_fp, 'w') as file:\n",
    "    yaml.dump(summary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba17300e-4d6a-4db4-b637-1c74e655bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cartesian combinations for sub-dictionaries\n",
    "sweep_evaluation_cartesian = generate_choice_combinations(sweep_evaluation_config)\n",
    "sweep_model_cartesian = generate_choice_combinations(sweep_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64215a1b-4d8b-40ac-abfe-3f99b2547b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate into main sweep dict\n",
    "\n",
    "model_config_key_name = model_type + \"_config\"\n",
    "sweep_config[model_config_key_name] = [sweep_model_cartesian[key] for key in sweep_model_cartesian]\n",
    "\n",
    "sweep_config['evaluation'] = [sweep_evaluation_cartesian[key] for key in sweep_evaluation_cartesian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6f5a46e-3313-48c9-816d-eee7f7028afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config_cartesian = generate_choice_combinations(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fee49b14-ee0a-49a0-9f1c-feaf386a87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number so as to get experiment names\n",
    "for i in sweep_config_cartesian.keys():\n",
    "    experiment_name = sweep_experiment_name + \"_\" + str(i)\n",
    "    sweep_config_cartesian[i]['experiment_name'] = experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a09a9744-038c-4e11-89d7-f985787d0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off configs:\n",
    "\n",
    "config_fps = []\n",
    "for i in sweep_config_cartesian.keys():\n",
    "    config = sweep_config_cartesian[i]\n",
    "    target_filename = config['experiment_name'] + '.yaml'\n",
    "    target_fp = os.path.join(sweep_experiment_dir, target_filename)\n",
    "    config_fps.append(target_fp)                         \n",
    "    with open(target_fp, 'w') as file:\n",
    "        yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1502533-2b0a-4436-8236-761c042333a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_model.py --config /home/jupyter/sweep_1/sweep_1_0.yaml; python train_model.py --config /home/jupyter/sweep_1/sweep_1_1.yaml; python train_model.py --config /home/jupyter/sweep_1/sweep_1_2.yaml; python train_model.py --config /home/jupyter/sweep_1/sweep_1_3.yaml; \n"
     ]
    }
   ],
   "source": [
    "# Generate command line prompt to run\n",
    "output = \"\"\n",
    "for config_fp in config_fps:\n",
    "    output += \"python train_model.py --config \" + config_fp + \"; \"\n",
    "\n",
    "print(output)\n",
    "#python train_model.py --config /home/jupyter/behavior_benchmarks/behavior_benchmarks/example_config/example_config_eskmeans.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521af43e-1925-4c2e-9c0e-15f4e1fdfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
