{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ce8245-b923-42ba-b1cf-b0a8bdb804d4",
   "metadata": {},
   "source": [
    "# Notebook to format data from \"Movement Sensor Dataset for Dog Behavior Classification\", Vehkaoja et al (2017).\n",
    "\n",
    "[Data is here](https://data.mendeley.com/datasets/vxhx934tbn/1) \n",
    "\n",
    "[Related paper is here](https://www.sciencedirect.com/science/article/pii/S0168159121001805#:~:text=Two%20sensor%20devices%20were%20attached,one%20on%20the%20neck%20collar.&text=The%20results%20were%20promising%3B%20the,yielded%2075%20%25%20accuracy%20at%20best.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77461baa-2d89-4ddf-b8b9-283f19b3313e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cd11e9-258b-4304-a21d-f826f276b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs:\n",
    "# formatted dataset directory\n",
    "# dataset_metadata (yaml), includes\n",
    "## sample_rate\n",
    "## dataset_label_names (list)\n",
    "## dataset_feature_names (list)\n",
    "## clip_ids (list)\n",
    "# clip_data (directory), includes\n",
    "## data_files (multiple files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7470e077-e978-495a-b349-27cc5a6b2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec388900-f0ab-4e41-a56b-9597e4f4911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import yaml\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc728a2-a91e-4da2-abea-4b57ceb4e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data filepaths\n",
    "\n",
    "raw_data_dir = '/home/jupyter/behavior_data_local/data/raw/vehkaoja_dogs'\n",
    "formatted_data_dir = '/home/jupyter/behavior_data_local/data/formatted/vehkaoja_dogs'\n",
    "\n",
    "if not os.path.exists(formatted_data_dir):\n",
    "    os.makedirs(formatted_data_dir)\n",
    "    \n",
    "data_fp = os.path.join(raw_data_dir, 'DogMoveData.csv')\n",
    "\n",
    "clip_data_dir = os.path.join(formatted_data_dir, 'clip_data')\n",
    "if not os.path.exists(clip_data_dir):\n",
    "    os.makedirs(clip_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6d55ef-3574-4052-9506-6c2d9af412cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up clip ids and metadata\n",
    "\n",
    "# Dataset metadata\n",
    "dataset_metadata = {}\n",
    "sr = 100\n",
    "dataset_metadata['sr'] = sr ## from dataset documentation\n",
    "dataset_metadata['dataset_name'] = 'vehkaoja_dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4adfe299-65f8-466a-9f05-3a6edb076aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cc6bef-abec-46aa-a11e-40564b9d0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clip_id(row):\n",
    "    return 'individual_' + str(row['DogID']) + '_test_' + str(row['TestNum'])\n",
    "\n",
    "data_full['clip_id'] = data_full.apply(create_clip_id, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "289d75dd-6fb9-44a5-9ac5-bea4c6fe24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the individual ids\n",
    "\n",
    "individual_ids = sorted(set(data_full['DogID']))\n",
    "dataset_metadata['individual_ids'] = individual_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe02421-9aeb-4fa3-8197-7d3497c4108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip ids\n",
    "clip_ids = sorted(set(data_full['clip_id']))  \n",
    "dataset_metadata['clip_ids'] = clip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c410f30-41bd-467e-992b-4bf5399d2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data splits by individual\n",
    "\n",
    "test_proportion = .25\n",
    "num_individuals = len(individual_ids)\n",
    "\n",
    "test_num_individuals = int(test_proportion * num_individuals)\n",
    "\n",
    "rng = np.random.default_rng(1280)\n",
    "test_individuals = list(rng.choice(individual_ids, size = test_num_individuals, replace = False))\n",
    "test_individuals.sort()\n",
    "\n",
    "train_individuals = individual_ids.copy()\n",
    "for i in test_individuals:\n",
    "    train_individuals.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea20959-639e-4f2c-8efa-945516302110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integer codes for individuals\n",
    "\n",
    "clip_id_to_individual_id = {clip_id : int(clip_id.split('_')[1]) for clip_id in clip_ids}\n",
    "dataset_metadata['clip_id_to_individual_id'] = clip_id_to_individual_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c3ee68-2436-4782-b8a8-bbeb354956df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clip_ids = []\n",
    "test_clip_ids = []\n",
    "for clip_id in clip_ids:\n",
    "    ind_id = clip_id_to_individual_id[clip_id]\n",
    "    train_clip_ids.append(clip_id) if ind_id in train_individuals else test_clip_ids.append(clip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca914b-f4d0-4265-b18c-71cd7aca2dc5",
   "metadata": {},
   "source": [
    "## Create dataset-level metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ee416-1f03-4891-8e99-caaf33773c3e",
   "metadata": {},
   "source": [
    "Each frame can be annotated with up to three behaviors simultaneously. We want to pare it down to a typical multi-class classification problem. We will eliminate some of the labels, since they typically occur coincidentally with other behaviors. After this, if frames have more than one label we call them `unknown`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2146239-1d30-45b5-8eaf-ba47823fd915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<undefined>', 'Bowing', 'Carrying object', 'Drinking', 'Eating', 'Extra_Synchronization', 'Galloping', 'Jumping', 'Lying chest', 'Pacing', 'Panting', 'Playing', 'Shaking', 'Sitting', 'Sniffing', 'Standing', 'Synchronization', 'Trotting', 'Tugging', 'Walking']\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the observed labels\n",
    "\n",
    "observed_labels = list(set(data_full['Behavior_1']).union(data_full['Behavior_3']).union(data_full['Behavior_3']))\n",
    "observed_labels.sort()\n",
    "\n",
    "print(observed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97edfab7-18ef-49e5-a076-e9e9493e3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    coincident_behaviors = {}\n",
    "    print(len(data_full))\n",
    "    for i, row in tqdm.tqdm(data_full.iterrows()):\n",
    "        row_behaviors = set(row[['Behavior_1', 'Behavior_2', 'Behavior_3']])\n",
    "        row_behaviors.discard('<undefined>')\n",
    "        row_behaviors = list(row_behaviors)\n",
    "        row_behaviors.sort()\n",
    "        row_behaviors = tuple(row_behaviors)\n",
    "        if row_behaviors not in coincident_behaviors:\n",
    "            coincident_behaviors[row_behaviors] = 0\n",
    "        coincident_behaviors[row_behaviors] += 1\n",
    "\n",
    "    {k: v for k, v in sorted(coincident_behaviors.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "409885d1-25fe-4508-9fc8-730480f9b5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n{('Playing', 'Tugging', 'Walking'): 3,\\n ('Bowing',): 4,\\n ('Panting', 'Playing', 'Standing'): 16,\\n ('Shaking', 'Synchronization'): 35,\\n ('Carrying object', 'Playing'): 44,\\n ('Lying chest', 'Playing'): 58,\\n ('Playing', 'Standing'): 60,\\n ('Carrying object', 'Shaking'): 91,\\n ('Eating', 'Panting', 'Sitting'): 95,\\n ('Playing', 'Walking'): 119,\\n ('Lying chest', 'Panting', 'Playing'): 174,\\n ('Carrying object', 'Playing', 'Walking'): 182,\\n ('Eating', 'Galloping'): 195,\\n ('Eating',): 219,\\n ('Carrying object', 'Playing', 'Standing'): 247,\\n ('Bowing', 'Eating'): 271,\\n ('Extra_Synchronization',): 287,\\n ('Playing', 'Shaking'): 303,\\n ('Pacing', 'Playing'): 382,\\n ('Carrying object', 'Playing', 'Shaking'): 384,\\n ('Eating', 'Pacing'): 449,\\n ('Eating', 'Panting', 'Standing'): 477,\\n ('Carrying object', 'Lying chest', 'Playing'): 687,\\n ('Carrying object', 'Pacing', 'Playing'): 1002,\\n ('Carrying object', 'Standing'): 1075,\\n ('Tugging',): 1134,\\n ('Bowing', 'Carrying object', 'Playing'): 1265,\\n ('Carrying object', 'Lying chest'): 1832,\\n ('Panting',): 2331,\\n ('Carrying object', 'Trotting'): 2780,\\n ('Carrying object', 'Jumping', 'Playing'): 3653,\\n ('Galloping',): 3668,\\n ('Playing', 'Trotting'): 6430,\\n ('Carrying object', 'Walking'): 6861,\\n ('Eating', 'Trotting'): 10752,\\n ('Synchronization',): 16720,\\n ('Jumping', 'Playing', 'Tugging'): 18199,\\n ('Jumping', 'Playing'): 20224,\\n ('Eating', 'Walking'): 25552,\\n ('Carrying object', 'Playing', 'Trotting'): 36445,\\n ('Shaking',): 41366,\\n ('Drinking',): 64721,\\n ('Pacing',): 76766,\\n ('Eating', 'Sitting'): 77448,\\n ('Eating', 'Lying chest'): 81368,\\n ('Galloping', 'Playing'): 81752,\\n ('Carrying object', 'Galloping', 'Playing'): 89311,\\n ('Eating', 'Standing'): 115980,\\n ('Playing', 'Tugging'): 277766,\\n ('Standing',): 370930,\\n ('Sitting',): 389467,\\n ('Playing',): 398320,\\n ('Lying chest',): 463266,\\n ('Panting', 'Standing'): 538925,\\n ('Lying chest', 'Panting'): 582517,\\n ('Panting', 'Sitting'): 653106,\\n ('Trotting',): 717472,\\n ('Walking',): 750318,\\n ('Sniffing',): 1026178,\\n (): 3649386}\\n \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output of the previous cell\n",
    "\n",
    "'''\n",
    "{('Playing', 'Tugging', 'Walking'): 3,\n",
    " ('Bowing',): 4,\n",
    " ('Panting', 'Playing', 'Standing'): 16,\n",
    " ('Shaking', 'Synchronization'): 35,\n",
    " ('Carrying object', 'Playing'): 44,\n",
    " ('Lying chest', 'Playing'): 58,\n",
    " ('Playing', 'Standing'): 60,\n",
    " ('Carrying object', 'Shaking'): 91,\n",
    " ('Eating', 'Panting', 'Sitting'): 95,\n",
    " ('Playing', 'Walking'): 119,\n",
    " ('Lying chest', 'Panting', 'Playing'): 174,\n",
    " ('Carrying object', 'Playing', 'Walking'): 182,\n",
    " ('Eating', 'Galloping'): 195,\n",
    " ('Eating',): 219,\n",
    " ('Carrying object', 'Playing', 'Standing'): 247,\n",
    " ('Bowing', 'Eating'): 271,\n",
    " ('Extra_Synchronization',): 287,\n",
    " ('Playing', 'Shaking'): 303,\n",
    " ('Pacing', 'Playing'): 382,\n",
    " ('Carrying object', 'Playing', 'Shaking'): 384,\n",
    " ('Eating', 'Pacing'): 449,\n",
    " ('Eating', 'Panting', 'Standing'): 477,\n",
    " ('Carrying object', 'Lying chest', 'Playing'): 687,\n",
    " ('Carrying object', 'Pacing', 'Playing'): 1002,\n",
    " ('Carrying object', 'Standing'): 1075,\n",
    " ('Tugging',): 1134,\n",
    " ('Bowing', 'Carrying object', 'Playing'): 1265,\n",
    " ('Carrying object', 'Lying chest'): 1832,\n",
    " ('Panting',): 2331,\n",
    " ('Carrying object', 'Trotting'): 2780,\n",
    " ('Carrying object', 'Jumping', 'Playing'): 3653,\n",
    " ('Galloping',): 3668,\n",
    " ('Playing', 'Trotting'): 6430,\n",
    " ('Carrying object', 'Walking'): 6861,\n",
    " ('Eating', 'Trotting'): 10752,\n",
    " ('Synchronization',): 16720,\n",
    " ('Jumping', 'Playing', 'Tugging'): 18199,\n",
    " ('Jumping', 'Playing'): 20224,\n",
    " ('Eating', 'Walking'): 25552,\n",
    " ('Carrying object', 'Playing', 'Trotting'): 36445,\n",
    " ('Shaking',): 41366,\n",
    " ('Drinking',): 64721,\n",
    " ('Pacing',): 76766,\n",
    " ('Eating', 'Sitting'): 77448,\n",
    " ('Eating', 'Lying chest'): 81368,\n",
    " ('Galloping', 'Playing'): 81752,\n",
    " ('Carrying object', 'Galloping', 'Playing'): 89311,\n",
    " ('Eating', 'Standing'): 115980,\n",
    " ('Playing', 'Tugging'): 277766,\n",
    " ('Standing',): 370930,\n",
    " ('Sitting',): 389467,\n",
    " ('Playing',): 398320,\n",
    " ('Lying chest',): 463266,\n",
    " ('Panting', 'Standing'): 538925,\n",
    " ('Lying chest', 'Panting'): 582517,\n",
    " ('Panting', 'Sitting'): 653106,\n",
    " ('Trotting',): 717472,\n",
    " ('Walking',): 750318,\n",
    " ('Sniffing',): 1026178,\n",
    " (): 3649386}\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e954b-384d-446b-adbf-8d6c3325e22f",
   "metadata": {},
   "source": [
    "Now we define the mapping from `observed_labels` to the `beh_labels` we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4676d9a6-0057-4073-b285-99b6c57bb16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We re-code each of the three behaviors according to the following:\n",
    "# This is following \"Dog behaviour classification with movement sensors placed on the harness and the collar\"\n",
    "# Except we include panting, because it is so strongly represented\n",
    "# We also include shaking, because the signal is so strong\n",
    "\n",
    "observed_labels_to_beh_label_first_pass = {'<undefined>' : 'unknown',\n",
    "                                           'Bowing' : 'unknown', \n",
    "                                           'Carrying object' : 'unknown', \n",
    "                                           'Drinking' : 'unknown', \n",
    "                                           'Eating' : 'unknown',\n",
    "                                           'Extra_Synchronization' : 'unknown',\n",
    "                                           'Galloping' : 'galloping',\n",
    "                                           'Jumping' : 'unknown', \n",
    "                                           'Lying chest' : 'lying_chest',\n",
    "                                           'Pacing' : 'unknown',\n",
    "                                           'Panting' : 'panting', # will get incorporated in second pass\n",
    "                                           'Playing' : 'unknown',\n",
    "                                           'Shaking' : 'shaking',\n",
    "                                           'Sitting' : 'sitting',\n",
    "                                           'Sniffing' : 'sniffing',\n",
    "                                           'Standing' : 'standing',\n",
    "                                           'Synchronization' : 'unknown',\n",
    "                                           'Trotting' : 'trotting',\n",
    "                                           'Tugging' : 'unknown', \n",
    "                                           'Walking' : 'walking'}\n",
    "\n",
    "# add the re-coded columns\n",
    "\n",
    "data_full['B1_beh'] = data_full['Behavior_1'].map(observed_labels_to_beh_label_first_pass)\n",
    "data_full['B2_beh'] = data_full['Behavior_2'].map(observed_labels_to_beh_label_first_pass)\n",
    "data_full['B3_beh'] = data_full['Behavior_3'].map(observed_labels_to_beh_label_first_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32a4549b-437b-4b90-99b0-294e936758a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these three columns to form single labels.\n",
    "\n",
    "def beh_label_first_pass_to_second_pass(row):\n",
    "    B1 = row['B1_beh']\n",
    "    B2 = row['B2_beh']\n",
    "    B3 = row['B3_beh']\n",
    "    all_beh = set([B1, B2, B3])\n",
    "    all_beh.discard('unknown')\n",
    "    if len(all_beh) == 0:\n",
    "        return 'unknown'\n",
    "    elif len(all_beh) > 2:\n",
    "        return 'unknown'\n",
    "    elif 'panting' in all_beh:\n",
    "        if 'standing' in all_beh:\n",
    "            return 'panting_standing'\n",
    "        elif 'sitting' in all_beh:\n",
    "            return 'panting_sitting'\n",
    "        elif 'lying_chest' in all_beh:\n",
    "            return 'panting_lying_chest'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    elif len(all_beh) == 1:\n",
    "        return all_beh.pop()\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253478f-104d-4e69-a09c-93f4107b59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to final beh_labels\n",
    "\n",
    "data_full['beh_label'] = data_full.apply(beh_label_first_pass_to_second_pass, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a3dc3-dfb0-4907-833e-8caf3eb4d88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integer codes for specific behaviors\n",
    "\n",
    "# list of behaviors (from Jeantet et al 2020)\n",
    "beh_names = set(data_full['beh_label'])\n",
    "beh_names.discard('unknown')\n",
    "beh_names = sorted(beh_names)\n",
    "beh_names.insert(0, 'unknown')\n",
    "\n",
    "dataset_metadata['label_names'] = beh_names\n",
    "\n",
    "beh_str_to_int = {name : i for i, name in enumerate(beh_names)}\n",
    "beh_int_to_str = {i : name for i, name in enumerate(beh_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7a11e-5510-4010-89d1-ccf095e2d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the observed labels?\n",
    "\n",
    "data_full['beh_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e7a7f-39b8-4765-bc74-414e5a951dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What are the annotation names in the data originally?\n",
    "\n",
    "data_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438d48f-0596-4a58-8669-358c9a4cec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clip_data column names\n",
    "\n",
    "clip_column_names = ['AccX_Back', 'AccY_Back', 'AccZ_Back', 'AccX_Neck',\n",
    "       'AccY_Neck', 'AccZ_Neck', 'GyrX_Back', 'GyrY_Back', 'GyrZ_Back', 'GyrX_Neck',\n",
    "       'GyrY_Neck', 'GyrZ_Neck', 'individual_id', 'label']\n",
    "dataset_metadata['clip_column_names'] = clip_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560ecfd-2ff8-4aff-a58c-76bb31200b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save off dataset level metadata\n",
    "\n",
    "dataset_metadata_fp = os.path.join(formatted_data_dir, 'dataset_metadata.yaml')\n",
    "\n",
    "with open(dataset_metadata_fp, 'w') as file:\n",
    "    yaml.dump(dataset_metadata, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964b042-2a2b-4690-bdd1-1685991ca77f",
   "metadata": {},
   "source": [
    "## Format Clip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa123d-88b9-4ccb-84d6-9f9f8767b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard practice is to remove gravitational bias from each accel channel by applying a boxcar filter, then subtract the result\n",
    "# We won't do that here, because the original article doesn't\n",
    "# Perhaps this is less important for terrestrial animals where pitch & roll doesn't change as dramatically?\n",
    "\n",
    "# def correct_gravitational_bias(series, window_dur_sec, sr = sr):\n",
    "#     window_dur_samples = int(window_dur_sec *sr)\n",
    "#     kernel = np.full(window_dur_samples, 1./ window_dur_samples)\n",
    "#     low_passed_series = np.convolve(series, kernel, mode = 'same')\n",
    "#     corrected_series = series - low_passed_series\n",
    "#     return corrected_series\n",
    "\n",
    "# # Convenience function to detect nans.\n",
    "# def nan_helper(y):\n",
    "#     return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "# #Interpolates all nan values of given array\n",
    "# def interpolate_nan(y):\n",
    "#     nans, x= nan_helper(y)\n",
    "#     y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d618a-e1ac-4b91-993b-2c1b50e1f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each clip, create and save the data in the correct format\n",
    "\n",
    "for clip_id in tqdm.tqdm(clip_ids):\n",
    "    # subselect features\n",
    "    clip_df = data_full[data_full['clip_id'] == clip_id]\n",
    "    clip_dur_samples = len(clip_df)\n",
    "    \n",
    "    # 'AccX_Back', 'AccY_Back', 'AccZ_Back', 'AccX_Neck',\n",
    "    # 'AccY_Neck', 'AccZ_Neck', 'GyrX_Back', 'GyrY_Back', 'GyrZ_Back', 'GyrX_Neck',\n",
    "    # 'GyrY_Neck', 'GyrZ_Neck', 'individual_id', 'label']\n",
    "    # collect and reformat\n",
    "    per_frame_AccX_Back = np.expand_dims(np.array(clip_df['ABack_x']), axis = -1)\n",
    "    per_frame_AccY_Back = np.expand_dims(np.array(clip_df['ABack_y']), axis = -1)\n",
    "    per_frame_AccZ_Back = np.expand_dims(np.array(clip_df['ABack_z']), axis = -1)\n",
    "    \n",
    "    per_frame_AccX_Neck = np.expand_dims(np.array(clip_df['ANeck_x']), axis = -1)\n",
    "    per_frame_AccY_Neck = np.expand_dims(np.array(clip_df['ANeck_y']), axis = -1)\n",
    "    per_frame_AccZ_Neck = np.expand_dims(np.array(clip_df['ANeck_z']), axis = -1)\n",
    "    \n",
    "    per_frame_GyrX_Back = np.expand_dims(np.array(clip_df['GBack_x']), axis = -1)\n",
    "    per_frame_GyrY_Back = np.expand_dims(np.array(clip_df['GBack_y']), axis = -1)\n",
    "    per_frame_GyrZ_Back = np.expand_dims(np.array(clip_df['GBack_z']), axis = -1)\n",
    "    \n",
    "    per_frame_GyrX_Neck = np.expand_dims(np.array(clip_df['GNeck_x']), axis = -1)\n",
    "    per_frame_GyrY_Neck = np.expand_dims(np.array(clip_df['GNeck_y']), axis = -1)\n",
    "    per_frame_GyrZ_Neck = np.expand_dims(np.array(clip_df['GNeck_z']), axis = -1)\n",
    "    \n",
    "    per_frame_annotations = np.expand_dims(np.array(clip_df['beh_label'].map(lambda x: beh_str_to_int[x])), axis = -1)\n",
    "    \n",
    "    individual_id = clip_id_to_individual_id[clip_id]\n",
    "    per_frame_individual_id = np.full_like(per_frame_annotations, individual_id)\n",
    "    \n",
    "    \n",
    "    clip_data = np.concatenate([per_frame_AccX_Back,\n",
    "                                per_frame_AccY_Back,\n",
    "                                per_frame_AccZ_Back,\n",
    "                                per_frame_AccX_Neck,\n",
    "                                per_frame_AccY_Neck,\n",
    "                                per_frame_AccZ_Neck,\n",
    "                                per_frame_GyrX_Back,\n",
    "                                per_frame_GyrY_Back,\n",
    "                                per_frame_GyrZ_Back,\n",
    "                                per_frame_GyrX_Neck,\n",
    "                                per_frame_GyrY_Neck,\n",
    "                                per_frame_GyrZ_Neck,\n",
    "                                per_frame_individual_id, \n",
    "                                per_frame_annotations], axis = 1)\n",
    "    \n",
    "    clip_data_fp = os.path.join(clip_data_dir, clip_id + '.npy')\n",
    "    np.save(clip_data_fp, clip_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9844300-e520-49a9-b975-210caa20a21f",
   "metadata": {},
   "source": [
    "## Check it all looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717812e0-af4e-4bd0-96db-5ce83ece61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_id = clip_ids[4]\n",
    "clip_data_fp = os.path.join(clip_data_dir, clip_id + '.npy')\n",
    "data = np.load(clip_data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77164f71-4257-43b1-ae76-49f1438c836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d243b7-ec2e-4bc5-8239-400cc7241953",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(data)[1]):\n",
    "    plt.plot(data[:50000, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e9c59-9f68-4ee9-9cfd-0d1ca21b5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d6022-f781-419c-aff8-ee25e1f3e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[115500:116000, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471c6a9-024b-4f69-bf60-445fe3801fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
